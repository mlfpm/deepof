{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import deepof.data\n",
    "import deepof.models\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda t: [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first batch\n",
    "dset11 = pd.ExcelFile(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_1/DLC_single_CDR1_1/1.Openfield_data-part1/JB05.1-OF-SI-part1.xlsx\"\n",
    ")\n",
    "dset12 = pd.ExcelFile(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_1/DLC_single_CDR1_1/2.Openfielddata-part2/AnimalID's-JB05.1-part2.xlsx\"\n",
    ")\n",
    "dset11 = pd.read_excel(dset11, \"Tabelle2\")\n",
    "dset12 = pd.read_excel(dset12, \"Tabelle2\")\n",
    "\n",
    "dset11.Test = dset11.Test.apply(lambda x: \"Test {}_s11\".format(x))\n",
    "dset12.Test = dset12.Test.apply(lambda x: \"Test {}_s12\".format(x))\n",
    "\n",
    "dset1 = {\"CSDS\":list(dset11.loc[dset11.Treatment.isin([\"CTR+CSDS\",\"NatCre+CSDS\"]), \"Test\"]) + \n",
    "                list(dset12.loc[dset12.Treatment.isin([\"CTR+CSDS\",\"NatCre+CSDS\"]), \"Test\"]),\n",
    "         \"NS\":  list(dset11.loc[dset11.Treatment.isin([\"CTR+nonstressed\",\"NatCre+nonstressed\"]), \"Test\"]) + \n",
    "                list(dset12.loc[dset12.Treatment.isin([\"CTR+nonstressed\",\"NatCre+nonstressed\"]), \"Test\"]),}\n",
    "\n",
    "dset1inv = {}\n",
    "for i in flatten(list(dset1.values())):\n",
    "    if i in dset1[\"CSDS\"]:\n",
    "        dset1inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset1inv[i] = \"NS\"\n",
    "        \n",
    "assert len(dset1inv) == dset11.shape[0] + dset12.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second batch\n",
    "dset21 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_2/Part1/2_Single/stressproject22.04.2020genotypes-openfieldday1.xlsx\"\n",
    ")\n",
    "dset22 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_2/Part2/2_Single/OpenFieldvideos-part2.xlsx\"\n",
    ")\n",
    "dset21.Test = dset21.Test.apply(lambda x: \"Test {}_s21\".format(x))\n",
    "dset22.Test = dset22.Test.apply(lambda x: \"Test {}_s22\".format(x))\n",
    "\n",
    "dset2 = {\"CSDS\":list(dset21.loc[dset21.Treatment == \"Stress\", \"Test\"]) + \n",
    "                list(dset22.loc[dset22.Treatment == \"Stressed\", \"Test\"]),\n",
    "         \"NS\":  list(dset21.loc[dset21.Treatment == \"Nonstressed\", \"Test\"]) +\n",
    "                list(dset22.loc[dset22.Treatment == \"Nonstressed\", \"Test\"])}\n",
    "\n",
    "dset2inv = {}\n",
    "for i in flatten(list(dset2.values())):\n",
    "    if i in dset2[\"CSDS\"]:\n",
    "        dset2inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset2inv[i] = \"NS\"\n",
    "        \n",
    "assert len(dset2inv) == dset21.shape[0] + dset22.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load third batch\n",
    "\n",
    "dset31 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_3/1.Day2OF-SIpart1/JB05 2Female-ELS-OF-SIpart1.xlsx\",\n",
    "    sheet_name=1\n",
    ")\n",
    "dset32 = pd.read_excel(\n",
    "    \"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_3/2.Day3OF-SIpart2/JB05 2FEMALE-ELS-OF-SIpart2.xlsx\",\n",
    "    sheet_name=1\n",
    ")\n",
    "dset31.Test = dset31.Test.apply(lambda x: \"Test {}_s31\".format(x))\n",
    "dset32.Test = dset32.Test.apply(lambda x: \"Test {}_s32\".format(x))\n",
    "\n",
    "dset3 = {\"CSDS\":[],\n",
    "         \"NS\":  list(dset31.loc[:, \"Test\"]) +\n",
    "                list(dset32.loc[:, \"Test\"])}\n",
    "\n",
    "dset3inv = {}\n",
    "for i in flatten(list(dset3.values())):\n",
    "    if i in dset3[\"CSDS\"]:\n",
    "        dset3inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset3inv[i] = \"NS\"\n",
    "        \n",
    "assert len(dset3inv) == dset31.shape[0] + dset32.shape[0], \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fourth batch\n",
    "dset41 = os.listdir(\"../../Desktop/deepof-data/tagged_videos/Individual_datasets/DLC_batch_4/JB05.4-OpenFieldvideos/\")\n",
    "\n",
    "# Remove empty video!\n",
    "dset41 = [vid for vid in dset41 if \"52\" not in vid]\n",
    "\n",
    "dset4 = {\"CSDS\":[],\n",
    "         \"NS\":  [i[:-4]+\"_s41\" for i in dset41]}\n",
    "\n",
    "dset4inv = {}\n",
    "for i in flatten(list(dset4.values())):\n",
    "    if i in dset4[\"CSDS\"]:\n",
    "        dset4inv[i] = \"CSDS\"\n",
    "    else:\n",
    "        dset4inv[i] = \"NS\"\n",
    "        \n",
    "assert len(dset4inv) == len(dset41), \"You missed some labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge phenotype dicts and serialise!\n",
    "aggregated_dset = {**dset1inv, **dset2inv, **dset3inv, **dset4inv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NS': 115, 'CSDS': 52})\n",
      "167\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(aggregated_dset.values()))\n",
    "print(115+52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aggregated dataset to disk\n",
    "import pickle\n",
    "with open(\"../../Desktop/deepof-data/deepof_single_topview/deepof_exp_conditions.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(aggregated_dset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and run project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 1.25 s, total: 16.1 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepof_main = deepof.data.project(path=os.path.join(\"..\",\"..\",\"Desktop\",\"deepof-data\",\"deepof_single_topview\"),\n",
    "                                  smooth_alpha=0.99,                                     \n",
    "                                  arena_dims=[380],\n",
    "                                  # exclude_bodyparts=[\"Tail_1\", \"Tail_2\", \"Tail_tip\", \"Tail_base\"],\n",
    "                                  exp_conditions=aggregated_dset\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trajectories...\n",
      "Smoothing trajectories...\n",
      "Interpolating outliers...\n",
      "Computing distances...\n",
      "Computing angles...\n",
      "Done!\n",
      "Coordinates of 2 videos across 2 conditions\n",
      "CPU times: user 2.13 s, sys: 331 ms, total: 2.47 s\n",
      "Wall time: 2.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepof_main = deepof_main.run(verbose=True)\n",
    "print(deepof_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quality = pd.concat([tab for tab in deepof_main.get_quality().values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_quality.boxplot(rot=45)\n",
    "plt.ylim(0.99985, 1.00001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ff39ef09fa4f51aa527f66c07fcee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='quality_top', max=1.0, step=0.01), Output()), _dom_câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(quality_top=(0., 1., 0.01))\n",
    "def low_quality_tags(quality_top):\n",
    "    pd.DataFrame(pd.melt(all_quality).groupby(\"bodyparts\").value.apply(\n",
    "        lambda y: sum(y<quality_top) / len(y) * 100)\n",
    "                ).sort_values(by=\"value\", ascending=False).plot.bar(rot=45)\n",
    "    \n",
    "    plt.xlabel(\"body part\")\n",
    "    plt.ylabel(\"Tags with quality under {} (%)\".format(quality_top * 100))\n",
    "    plt.tight_layout()\n",
    "    plt.legend([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "deepof_coords = deepof_main.get_coords(polar=False, speed=0, align=\"Spine_1\", align_inplace=True, propagate_labels=False)\n",
    "#deepof_dists  = deepof_main.get_distances(propagate_labels=False)\n",
    "#deepof_angles = deepof_main.get_angles(propagate_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"Preprocessing training set...\")\n",
    "deepof_train = deepof_coords.preprocess(\n",
    "    window_size=24,\n",
    "    window_step=24,\n",
    "    conv_filter=None,\n",
    "    scale=\"standard\",\n",
    "    shuffle=True,\n",
    "    test_videos=0,\n",
    ")[0]\n",
    "\n",
    "print(\"Loading pre-trained model...\")\n",
    "encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "    loss=\"ELBO\",\n",
    "    number_of_components=20,\n",
    "    compile_model=True,\n",
    "    kl_warmup_epochs=20,\n",
    "    montecarlo_kl=10,\n",
    "    encoding=6,\n",
    "    mmd_warmup_epochs=20,\n",
    "    predictor=0,\n",
    "    phenotype_prediction=0,\n",
    ").build(deepof_train.shape)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"../../Desktop/deepof-data/trained_weights/dimension_and_loss_experiments_24frames/GMVAE_loss=ELBO_encoding=6_k=20_run_0_final_weights.h5\"\n",
    "#weights = [tpath+i for i in os.listdir(tpath) if \"run_0\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_network = weights\n",
    "print(trained_network)\n",
    "l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "pheno = 0# float(re.findall(\"pheno=(.+?)_\", trained_network)[0])\n",
    "\n",
    "encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "    loss=\"ELBO\",\n",
    "    number_of_components=k,\n",
    "    compile_model=True,\n",
    "    kl_warmup_epochs=20,\n",
    "    montecarlo_kl=10,\n",
    "    encoding=l,\n",
    "    mmd_warmup_epochs=20,\n",
    "    predictor=0,\n",
    "    phenotype_prediction=pheno,\n",
    ").build(deepof_train.shape)[:4]\n",
    "\n",
    "gmvaep.load_weights(trained_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to pass through the models\n",
    "trained_distribution = encoder(deepof_train[:10000])\n",
    "categories = tf.keras.models.Model(encoder.input, encoder.layers[13].output)(deepof_train[:10000]).numpy()\n",
    "\n",
    "# Fit a scaler to unscale the reconstructions later on\n",
    "video_key = np.random.choice(list(deepof_coords.keys()), 1)[0]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.array(pd.concat(list(deepof_coords.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve latent distribution parameters and sample from posterior\n",
    "def get_median_params(component, categories, cluster, param):\n",
    "    # means = [np.median(component.mean().numpy(), axis=0) for component in mix_components]\n",
    "    # stddevs = [np.median(component.stddev().numpy(), axis=0) for component in mix_components]\n",
    "    if param == \"mean\":\n",
    "        component = component.mean().numpy()\n",
    "    elif param == \"stddev\":\n",
    "        component = component.stddev().numpy()\n",
    "    \n",
    "    cluster_select = np.argmax(categories, axis=1)==cluster\n",
    "    if np.sum(cluster_select) == 0:\n",
    "        return None\n",
    "    component = component[cluster_select]\n",
    "    return np.median(component, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_latent_parameters(distribution, reduce=False, plot=False, categories=None, filt=0, save=True):\n",
    "    mix_components = distribution.components\n",
    "    \n",
    "    # The main problem is here! We need to select only those training instances in which a given cluster was selected. \n",
    "    # Then compute the median for those only\n",
    "    \n",
    "    means = [get_median_params(component, categories, i, \"mean\") for i,component in enumerate(mix_components)]\n",
    "    stddevs = [get_median_params(component, categories, i, \"stddev\") for i,component in enumerate(mix_components)]\n",
    "    means = [i for i in means if i is not None]\n",
    "    stddevs = [i for i in stddevs if i is not None]\n",
    "    \n",
    "    if filter:\n",
    "        filts = np.max(categories, axis=0) > filt\n",
    "        means = [i for i,j in zip(means, filts) if j]\n",
    "        stddevs = [i for i,j in zip(stddevs, filts) if j]\n",
    "    \n",
    "    if reduce:\n",
    "        data = [np.random.normal(size=[1000, len(means[0])],\n",
    "                                 loc=meanvec, \n",
    "                                 scale=stddevvec)[:,np.newaxis] for meanvec, stddevvec in zip(means, stddevs)]\n",
    "        data = np.concatenate(data, axis=1).reshape([1000*len(means), len(means[0])])        \n",
    "        reducer = PCA(n_components=3)\n",
    "        data = reducer.fit_transform(data)\n",
    "        data = data.reshape([1000, len(means), 3])\n",
    "        \n",
    "    if plot == 2:\n",
    "        for i in range(len(means)):\n",
    "            plt.scatter(data[:,i,0], data[:,i,1], label=i)\n",
    "        plt.title(\"Mean representation of latent space - K={}/{} - L={} - filt={}\".format(len(means), \n",
    "                                                                                          len(mix_components), \n",
    "                                                                                          len(means[0]), filt))        \n",
    "        plt.xlabel(\"PCA 1\")\n",
    "        plt.ylabel(\"PCA 2\")\n",
    "        #plt.legend()\n",
    "        if save:\n",
    "            plt.savefig(\"Mean representation of latent space - K={}.{} - L={} - filt={}.png\".format(len(means), \n",
    "                                                                                          len(mix_components), \n",
    "                                                                                          len(means[0]), filt).replace(\" \", \"_\"))\n",
    "        plt.show()\n",
    "        \n",
    "    elif plot == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for i in range(len(means)):\n",
    "            ax.scatter(data[:,i,0], data[:,i,1], data[:,i,2], label=i)\n",
    "        plt.title(\"Mean representation of latent space - K={}/{} - L={} - filt={}\".format(len(means), \n",
    "                                                                                          len(mix_components), \n",
    "                                                                                          len(means[0]), filt))\n",
    "        ax.set_xlabel(\"PCA 1\")\n",
    "        ax.set_ylabel(\"PCA 2\")\n",
    "        ax.set_zlabel(\"PCA 3\")\n",
    "        #plt.legend()\n",
    "        if save:\n",
    "            plt.savefig(\"Mean representation of latent space - K={}.{} - L={} - filt={}.png\".format(len(means), \n",
    "                                                                                          len(mix_components), \n",
    "                                                                                          len(means[0]), filt).replace(\" \", \"_\"))\n",
    "        plt.show()\n",
    "    \n",
    "    elif plot > 3:\n",
    "        raise ValueError(\"Can't plot in more than 3 dimensions!\")\n",
    "    \n",
    "    return means, stddevs\n",
    "\n",
    "def sample_from_posterior(decoder, parameters, component, enable_variance=False, video_output=False, samples=1):\n",
    "    means, stddevs = parameters\n",
    "    sample = np.random.normal(size=[samples, len(means[component])], loc=means[component], scale=(stddevs[component] if enable_variance else 0))\n",
    "    reconstruction = decoder(sample).mean()\n",
    "    \n",
    "    if video_output:\n",
    "        scaled_video_rec = scaler.inverse_transform(reconstruction)\n",
    "        scaled_video_rec = scaled_video_rec.reshape(\n",
    "            [samples*scaled_video_rec.shape[1], scaled_video_rec.shape[2]]\n",
    "        )\n",
    "        columns = deepof_coords[list(deepof_coords.keys())[0]].columns\n",
    "        scaled_video_rec = pd.DataFrame(scaled_video_rec, columns=columns)\n",
    "\n",
    "        ### VIDEO OUTPUT ###\n",
    "        w = 400\n",
    "        h = 400\n",
    "        factor = 2.5\n",
    "\n",
    "        # Instantiate video\n",
    "        writer = cv2.VideoWriter()\n",
    "        writer.open(\n",
    "            \"Reconstruction_test_L={}_k={}_pheno={}_component={}_video.avi\".format(l,k,pheno,component),\n",
    "            cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "            24,\n",
    "            (int(w * factor), int(h * factor)),\n",
    "            True,\n",
    "        )\n",
    "\n",
    "        for frame in tqdm.tqdm(range(scaled_video_rec.shape[0])):\n",
    "\n",
    "            image = np.zeros((h, w, 3), np.uint8) + 30\n",
    "            for bpart in scaled_video_rec.columns.levels[0]:\n",
    "\n",
    "                try:\n",
    "                    pos = (\n",
    "                        (-int(scaled_video_rec[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "                        (-int(scaled_video_rec[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "                    )\n",
    "\n",
    "                    cv2.circle(image, pos, 2, (0, 0, 255), -1)\n",
    "\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "            # draw skeleton\n",
    "            def draw_line(start, end, df, col):\n",
    "                for bpart in end:\n",
    "                    cv2.line(\n",
    "                        image,\n",
    "                        tuple(-df[start].loc[frame, :].astype(int) + w // 2),\n",
    "                        tuple(-df[bpart].loc[frame, :].astype(int) + h // 2),\n",
    "                        col,\n",
    "                        1,\n",
    "                    )\n",
    "\n",
    "            col = (0,0,255)\n",
    "            draw_line(\"Nose\", [\"Left_ear\", \"Right_ear\"], scaled_video_rec, col)\n",
    "            draw_line(\"Spine_1\", [\"Left_ear\", \"Right_ear\", \"Left_fhip\", \"Right_fhip\"], scaled_video_rec, col)\n",
    "            draw_line(\"Spine_2\", [\"Spine_1\", \"Left_bhip\", \"Right_bhip\"], scaled_video_rec, col)\n",
    "            #draw_line(\"Tail_1\", [\"Tail_base\", \"Tail_2\"], scaled_video_rec, col)\n",
    "            #draw_line(\"Tail_tip\", [\"Tail_2\"], scaled_video_rec, col)\n",
    "\n",
    "            image = cv2.resize(image, (0, 0), fx=factor, fy=factor)\n",
    "            writer.write(image)\n",
    "\n",
    "        writer.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stddevs = retrieve_latent_parameters(trained_distribution, categories=categories, reduce=True, plot=3, filt=0.9, save=True)\n",
    "for i in range(0, 20):\n",
    "    reconst = sample_from_posterior(decoder, (means, stddevs), i, enable_variance=True, video_output=True, samples=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_key = np.random.choice(list(deepof_coords.keys()), 1)[0]\n",
    "# video_input = deepof.data.table_dict({video_key:deepof_coords[video_key]}, typ=\"coords\").preprocess(\n",
    "#                                                                                                 window_size=11,\n",
    "#                                                                                                 window_step=1,\n",
    "#                                                                                                 conv_filter=None,\n",
    "#                                                                                                 scale=\"standard\",\n",
    "#                                                                                                 shuffle=False,\n",
    "#                                                                                                 test_videos=0,\n",
    "#                                                                                             )[0]\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(np.array(pd.concat(list(deepof_coords.values()))))\n",
    "\n",
    "# for trained_network in tqdm.tqdm(weights):\n",
    "    \n",
    "#     l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "#     k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "#     pheno = float(re.findall(\"pheno=(.+?)_\", trained_network)[0])\n",
    "    \n",
    "#     encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "#         loss=\"ELBO\",\n",
    "#         number_of_components=k,\n",
    "#         compile_model=True,\n",
    "#         kl_warmup_epochs=20,\n",
    "#         montecarlo_kl=10,\n",
    "#         encoding=l,\n",
    "#         mmd_warmup_epochs=20,\n",
    "#         predictor=0,\n",
    "#         phenotype_prediction=pheno,\n",
    "#     ).build(video_input.shape)[:4]\n",
    "    \n",
    "#     gmvaep.load_weights(trained_network)\n",
    "    \n",
    "\n",
    "#     # Get reconstruction\n",
    "#     video_pred = gmvaep.predict(video_input)[0][:, 6, :]\n",
    "\n",
    "#     # Get encodings\n",
    "#     # video_clusters = grouper.predict(video_input)\n",
    "#     # video_encodings = encoder.predict(video_input)\n",
    "\n",
    "#     scaled_video_pred = scaler.inverse_transform(video_pred)\n",
    "#     scaled_video_input = scaler.inverse_transform(video_input[:, 6, :])\n",
    "\n",
    "#     scaled_video_input = pd.DataFrame(scaled_video_input, columns=deepof_coords[video_key].columns)\n",
    "#     scaled_video_pred = pd.DataFrame(scaled_video_pred, columns=deepof_coords[video_key].columns)\n",
    "    \n",
    "#     ### VIDEO OUTPUT ###\n",
    "#     w = 400\n",
    "#     h = 400\n",
    "#     factor = 2.5\n",
    "\n",
    "#     # Instantiate video\n",
    "#     writer = cv2.VideoWriter()\n",
    "#     writer.open(\n",
    "#         \"L={}_k={}_pheno={}_run0_video.avi\".format(l,k,pheno),\n",
    "#         cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "#         24,\n",
    "#         (int(w * factor), int(h * factor)),\n",
    "#         True,\n",
    "#     )\n",
    "\n",
    "#     for frame in tqdm.tqdm(range(250)):\n",
    "\n",
    "#         image = np.zeros((h, w, 3), np.uint8) + 30\n",
    "#         for bpart in scaled_video_input.columns.levels[0]:\n",
    "\n",
    "#             try:\n",
    "#                 pos = (\n",
    "#                     (-int(scaled_video_input[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "#                     (-int(scaled_video_input[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "#                 )\n",
    "\n",
    "#                 pos_pred = (\n",
    "#                     (-int(scaled_video_pred[bpart].loc[frame, \"x\"]) + w // 2),\n",
    "#                     (-int(scaled_video_pred[bpart].loc[frame, \"y\"]) + h // 2),\n",
    "#                 )\n",
    "\n",
    "#                 cv2.circle(image, pos, 2, (0, 0, 255), -1)\n",
    "#                 cv2.circle(image, pos_pred, 2, (0, 255, 0), -1)\n",
    "\n",
    "#             except KeyError:\n",
    "#                 continue\n",
    "\n",
    "#         # draw skeleton\n",
    "#         def draw_line(start, end, df, col):\n",
    "#             for bpart in end:\n",
    "#                 cv2.line(\n",
    "#                     image,\n",
    "#                     tuple(-df[start].loc[frame, :].astype(int) + w // 2),\n",
    "#                     tuple(-df[bpart].loc[frame, :].astype(int) + h // 2),\n",
    "#                     col,\n",
    "#                     1,\n",
    "#                 )\n",
    "\n",
    "#         for df, col in zip([scaled_video_input, scaled_video_pred], [(0,0,255),(0,255,0)]):\n",
    "#             draw_line(\"Nose\", [\"Left_ear\", \"Right_ear\"], df, col)\n",
    "#             draw_line(\"Spine_1\", [\"Left_ear\", \"Right_ear\", \"Left_fhip\", \"Right_fhip\"], df, col)\n",
    "#             draw_line(\"Spine_2\", [\"Spine_1\", \"Tail_base\", \"Left_bhip\", \"Right_bhip\"], df, col)\n",
    "#             draw_line(\"Tail_1\", [\"Tail_base\", \"Tail_2\"], df, col)\n",
    "#             draw_line(\"Tail_tip\", [\"Tail_2\"], df, col)\n",
    "\n",
    "#         image = cv2.resize(image, (0, 0), fx=factor, fy=factor)\n",
    "#         writer.write(image)\n",
    "\n",
    "#     writer.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_corrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Plot latent space!\n",
    "X_train = deepof_coords.preprocess(\n",
    "                            window_size=11,\n",
    "                            window_step=1,\n",
    "                            conv_filter=None,\n",
    "                            scale=\"standard\",\n",
    "                            shuffle=True,\n",
    "                            test_videos=0,\n",
    "                        )[0]\n",
    "\n",
    "samples = 10000\n",
    "X_train = X_train[:samples]\n",
    "\n",
    "for trained_network in tqdm.tqdm(weights):\n",
    "    print(trained_network)\n",
    "    \n",
    "    l = int(re.findall(\"encoding=(\\d+)_\", trained_network)[0])\n",
    "    k = int(re.findall(\"k=(\\d+)_\", trained_network)[0])\n",
    "    pheno = float(re.findall(\"pheno=(.+?)_\", trained_network)[0])\n",
    "\n",
    "    \n",
    "    encoder, decoder, grouper, gmvaep, = deepof.models.SEQ_2_SEQ_GMVAE(\n",
    "        loss=\"ELBO\",\n",
    "        number_of_components=k,\n",
    "        compile_model=True,\n",
    "        kl_warmup_epochs=20,\n",
    "        montecarlo_kl=10,\n",
    "        encoding=l,\n",
    "        mmd_warmup_epochs=20,\n",
    "        predictor=0,\n",
    "        phenotype_prediction=pheno,\n",
    "    ).build(X_train.shape)[:4]\n",
    "    \n",
    "    gmvaep.load_weights(trained_network)\n",
    "\n",
    "    # Get encodings\n",
    "    pheno_pred = gmvaep.predict(X_train)[1]\n",
    "    clusters = grouper.predict(X_train)\n",
    "    encodings = encoder.predict(X_train)\n",
    "    \n",
    "#     # For each cluster, compute correlation between pheno prediction and cluster weight\n",
    "#     pheno_corr = []\n",
    "#     for i in range(k):\n",
    "#         pheno_corr.append(np.corrcoef(clusters[:,i], np.squeeze(pheno_pred))[0,1])\n",
    "#     pheno_corrs[\"L={}_k={}_pheno={}_run0\".format(l,k, pheno)] = pheno_corr\n",
    "    \n",
    "    reducer = umap.UMAP(n_components=2)\n",
    "    encodings = reducer.fit_transform(encodings)\n",
    "    \n",
    "    sns.scatterplot(encodings[:,0], encodings[:,1], \n",
    "                hue=np.squeeze(pheno_pred),#np.argmax(clusters, axis=1).astype(int).astype(str),\n",
    "                #palette=(\"jet\" if k>1 else None), legend=\"none\")\n",
    "                   )\n",
    "    plt.title(\"GMVAE Latent space representation: L={}; k={}\".format(l,k))\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.legend([],[], frameon=False)\n",
    "    plt.savefig(\"L={}_k={}_pheno={}_run0_latent_space_phenohue.pdf\".format(l,k, pheno))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pheno_pred.shape)\n",
    "print(clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation density plots\n",
    "pweights = [0.01, 0.1, 0.5, 0.25, 1, 2, 4, 10, 100]\n",
    "for i in pweights:\n",
    "    corrs = {k:v for k,v in pheno_corrs.items() if str(i) in k}\n",
    "    sns.kdeplot(np.concatenate([i for i in corrs.values()]), label=str(i))\n",
    "    plt.xlabel(\"pearson correlation coefficient\")\n",
    "    plt.ylabel(\"density\")\n",
    "    \n",
    "plt.savefig(\"deepof_pheno_fullcorrhistogram.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation density plots\n",
    "pweights = [0.01, 0.1, 0.5, 0.25, 1, 2, 4, 10, 100]\n",
    "for i in pweights:\n",
    "    corrs = {k:v for k,v in pheno_corrs.items() if str(i) in k}\n",
    "    sns.kdeplot(np.concatenate([i for i in corrs.values()]), label=str(i))\n",
    "    plt.xlabel(\"pearson correlation coefficient\")\n",
    "    plt.ylabel(\"density\")\n",
    "    \n",
    "plt.savefig(\"deepof_pheno_parccorrhistogram.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(gmvaep, show_shapes=True, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=True, dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encodings(data, samples, n, clusters, threshold, highlight=None):\n",
    "    \n",
    "    reducer  = LinearDiscriminantAnalysis(n_components=n)\n",
    "    clusters = clusters[:samples, :]\n",
    "    \n",
    "    # filter   = np.max(np.mean(clusters, axis=0), axis=1) > threshold\n",
    "    \n",
    "    clusters = np.argmax(clusters, axis=1)#[filter]\n",
    "    rep = reducer.fit_transform(data[:samples], clusters)\n",
    "\n",
    "    if n == 2:\n",
    "        df = pd.DataFrame({\"encoding-1\":rep[:,0],\"encoding-2\":rep[:,1],\"clusters\":[\"A\"+str(i) for i in clusters]})\n",
    "\n",
    "        enc = px.scatter(data_frame=df, x=\"encoding-1\", y=\"encoding-2\",\n",
    "                           color=\"clusters\", width=600, height=600,\n",
    "                           color_discrete_sequence=px.colors.qualitative.T10)\n",
    "                \n",
    "        #if highlight:\n",
    "        #    ig.add_trace(go.Scatter(x=, y=)\n",
    "\n",
    "    elif n == 3:\n",
    "        df3d = pd.DataFrame({\"encoding-1\":rep[:,0],\"encoding-2\":rep[:,1],\"encoding-3\":rep[:,2],\n",
    "                         \"clusters\":[\"A\"+str(i) for i in clusters]})\n",
    "\n",
    "        enc = px.scatter_3d(data_frame=df3d, x=\"encoding-1\", y=\"encoding-2\", z=\"encoding-3\",\n",
    "                           color=\"clusters\", width=600, height=600,\n",
    "                           color_discrete_sequence=px.colors.qualitative.T10)\n",
    "\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encodings(encoder.predict(deepof_train[:10000]), 1000, 2, categories, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, y_train, X_test, y_test = deepof_coords.preprocess(window_size=11, window_step=11, conv_filter=None, sigma=55,\n",
    "                                                            shift=0, scale='standard', align='all', shuffle=True, test_videos=5)\n",
    "print(\"Train dataset shape: \", X_train.shape)\n",
    "print(\"Train dataset shape: \", y_train.shape)\n",
    "print(\"Test dataset shape: \", X_test.shape)\n",
    "print(\"Test dataset shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models and get learning rate (1-cycle policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq 2 seq Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow.keras as k\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'Baseline_AE'\n",
    "log_dir = os.path.abspath(\n",
    "    \"logs/fit/{}_{}\".format(NAME, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    ")\n",
    "tensorboard_callback = k.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepof.models import SEQ_2_SEQ_AE, SEQ_2_SEQ_GMVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, ae = SEQ_2_SEQ_AE().build(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "encoder, generator, grouper, gmvaep, kl_warmup_callback, mmd_warmup_callback = SEQ_2_SEQ_GMVAE(loss='ELBO',\n",
    "                                                                               compile_model=True,\n",
    "                                                                               number_of_components=10,\n",
    "                                                                               kl_warmup_epochs=20,\n",
    "                                                                               mmd_warmup_epochs=0,\n",
    "                                                                               predictor=0,\n",
    "                                                                               phenotype_prediction=0,\n",
    "                                                                               architecture_hparams={\"encoding\":2}\n",
    "                                                                                ).build(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "rates, losses = deepof.model_utils.find_learning_rate(gmvaep, deepof_train[:512*10], deepof_test[:512*10], epochs=1, batch_size=batch_size)\n",
    "deepof.model_utils.plot_lr_vs_loss(rates, losses)\n",
    "plt.title(\"Learning rate tuning\")\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gmvaep.fit(\n",
    "                    x=X_train,\n",
    "                    y=X_train,\n",
    "                    epochs=1,\n",
    "                    batch_size=128,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, [X_test, y_test]),\n",
    "                    callbacks=[kl_warmup_callback],\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pttest\n",
    "samples = 15000\n",
    "montecarlo = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"GMVAE_components=30_loss=ELBO_kl_warmup=30_mmd_warmup=30_20200804-225526_final_weights.h5\"\n",
    "\n",
    "gmvaep.load_weights(weights)\n",
    "\n",
    "if montecarlo:\n",
    "    clusts = np.stack([grouper(data[:samples]) for sample in (tqdm(range(montecarlo)))])\n",
    "    clusters = clusts.mean(axis=0)\n",
    "    clusters = np.argmax(clusters, axis=1)\n",
    "    \n",
    "else:\n",
    "    clusters = grouper(data[:samples], training=False)\n",
    "\n",
    "    \n",
    "    clusters = np.argmax(clusters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_encodings(data, samples, n, clusters, threshold):\n",
    "    \n",
    "    reducer  = PCA(n_components=n)\n",
    "    clusters = clusters[:, :samples]\n",
    "    filter   = np.max(np.mean(clusters, axis=0), axis=1) > threshold\n",
    "    encoder.predict(data[:samples][filter])\n",
    "    print(\"{}/{} samples used ({}%); confidence threshold={}\".format(sum(filter),\n",
    "                                                                     samples,\n",
    "                                                                     sum(filter)/samples*100,\n",
    "                                                                     threshold))\n",
    "    \n",
    "    clusters = np.argmax(np.mean(clusters, axis=0), axis=1)[filter]\n",
    "    rep = reducer.fit_transform(encoder.predict(data[:samples][filter]))\n",
    "\n",
    "    if n == 2:\n",
    "        df = pd.DataFrame({\"encoding-1\":rep[:,0],\"encoding-2\":rep[:,1],\"clusters\":[\"A\"+str(i) for i in clusters]})\n",
    "\n",
    "        enc = px.scatter(data_frame=df, x=\"encoding-1\", y=\"encoding-2\",\n",
    "                           color=\"clusters\", width=600, height=600,\n",
    "                           color_discrete_sequence=px.colors.qualitative.T10)\n",
    "\n",
    "\n",
    "    elif n == 3:\n",
    "        df3d = pd.DataFrame({\"encoding-1\":rep[:,0],\"encoding-2\":rep[:,1],\"encoding-3\":rep[:,2],\n",
    "                         \"clusters\":[\"A\"+str(i) for i in clusters]})\n",
    "\n",
    "        enc = px.scatter_3d(data_frame=df3d, x=\"encoding-1\", y=\"encoding-2\", z=\"encoding-3\",\n",
    "                           color=\"clusters\", width=600, height=600,\n",
    "                           color_discrete_sequence=px.colors.qualitative.T10)\n",
    "\n",
    "    return enc\n",
    "\n",
    "plot_encodings(data, 5000, 2, clusts, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence distribution per cluster\n",
    "for cl in range(5):\n",
    "    cl_select = np.argmax(np.mean(clusts, axis=0), axis=1) == cl\n",
    "    dt = np.mean(clusts[:,cl_select,cl], axis=0)\n",
    "    sns.kdeplot(dt, shade=True, label=cl)\n",
    "    \n",
    "plt.xlabel('MC Dropout confidence')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animated_cluster_heatmap(data, clust, clusters, threshold=0.75, samples=False):\n",
    "    \n",
    "    if not samples:\n",
    "        samples = data.shape[0]\n",
    "    tpoints = data.shape[1]\n",
    "    bdparts = data.shape[2] // 2\n",
    "    \n",
    "    cls = clusters[:,:samples,:]\n",
    "    filt = np.max(np.mean(cls, axis=0), axis=1) > threshold\n",
    "    \n",
    "    cls = np.argmax(np.mean(cls, axis=0), axis=1)[filt]\n",
    "    clust_series = data[:samples][filt][cls==clust]\n",
    "        \n",
    "    rshape = clust_series.reshape(clust_series.shape[0]*clust_series.shape[1],\n",
    "                                  clust_series.shape[2])\n",
    "    \n",
    "    cluster_df = pd.DataFrame()\n",
    "    cluster_df['x'] = rshape[:,[0,2,4,6,8,10]].flatten(order='F')\n",
    "    cluster_df['y'] = rshape[:,[1,3,5,7,9,11]].flatten(order='F')\n",
    "    cluster_df['bpart'] = np.tile(np.repeat(np.arange(bdparts),\n",
    "                                            clust_series.shape[0]), tpoints)\n",
    "    cluster_df['frame'] = np.tile(np.repeat(np.arange(tpoints),\n",
    "                                            clust_series.shape[0]), bdparts)\n",
    "        \n",
    "    fig = px.density_contour(data_frame=cluster_df, x='x', y='y', animation_frame='frame',\n",
    "                     width=600, height=600, \n",
    "                     color='bpart',color_discrete_sequence=px.colors.qualitative.T10)\n",
    "\n",
    "    fig.update_traces(contours_coloring=\"fill\", \n",
    "                      contours_showlabels = True)\n",
    "    \n",
    "    fig.update_xaxes(range=[-3, 3])\n",
    "    fig.update_yaxes(range=[-3, 3])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animated_cluster_heatmap(pttest, 4, clusts, samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [i for i in os.listdir() if \"GMVAE\" in i and \".h5\" in i]\n",
    "mult_clusters = np.zeros([len(weights), samples])\n",
    "mean_conf = []\n",
    "\n",
    "for k,i in tqdm(enumerate(sorted(weights))):\n",
    "    print(i)\n",
    "    gmvaep.load_weights(i)\n",
    "\n",
    "    if montecarlo:\n",
    "        clusters = np.stack([grouper(data[:samples]) for sample in (tqdm(range(montecarlo)))])\n",
    "        clusters = clusters.mean(axis=0)\n",
    "        mean_conf.append(clusters.max(axis=1))\n",
    "        clusters = np.argmax(clusters, axis=1)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        clusters = grouper(data[:samples], training=False)\n",
    "        mean_conf.append(clusters.max(axis=1))\n",
    "        clusters = np.argmax(clusters, axis=1)\n",
    "        \n",
    "    mult_clusters[k] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.95\n",
    "ari_dist = []\n",
    "\n",
    "for i,k in enumerate(combinations(range(len(weights)),2)):\n",
    "    filt = ((mean_conf[k[0]] > thr) & (mean_conf[k[1]]>thr))\n",
    "    \n",
    "    ari = adjusted_rand_score(mult_clusters[k[0]][filt],\n",
    "                              mult_clusters[k[1]][filt])\n",
    "    \n",
    "    ari_dist.append(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ari = []\n",
    "for i in tqdm(range(6)):\n",
    "    random_ari.append(adjusted_rand_score(np.random.uniform(0,6,50).astype(int),\n",
    "                                          np.random.uniform(0,6,50).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(ari_dist, label=\"ARI gmvaep\", shade=True)\n",
    "sns.kdeplot(random_ari, label=\"ARI random\", shade=True)\n",
    "\n",
    "plt.xlabel(\"Normalised Adjusted Rand Index\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster differences across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DLCS1_coords = DLC_social_1_coords.get_coords(center=\"B_Center\",polar=False, length='00:10:00', align='B_Nose')\n",
    "\n",
    "Treatment_coords = {}\n",
    "\n",
    "for cond in Treatment_dict.keys():\n",
    "    Treatment_coords[cond] = DLCS1_coords.filter(Treatment_dict[cond]).preprocess(window_size=13, \n",
    "                                                 window_step=10, filter=None, scale='standard', align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "montecarlo = 10\n",
    "\n",
    "Predictions_per_cond = {}\n",
    "Confidences_per_cond = {}\n",
    "\n",
    "for cond in Treatment_dict.keys():\n",
    "    \n",
    "    Predictions_per_cond[cond] = np.stack([grouper(Treatment_coords[cond]\n",
    "                         ) for sample in (tqdm(range(montecarlo)))])\n",
    "\n",
    "    Confidences_per_cond[cond] = np.mean(Predictions_per_cond[cond], axis=0)\n",
    "    Predictions_per_cond[cond] = np.argmax(Confidences_per_cond[cond], axis=1) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Predictions_per_condition = {k:{cl:[] for cl in range(1,31)} for k in Treatment_dict.keys()}\n",
    "\n",
    "for k in Predictions_per_cond.values():\n",
    "    print(Counter(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in Treatment_dict.keys():\n",
    "    start = 0\n",
    "    for i,j in enumerate(DLCS1_coords.filter(Treatment_dict[cond]).values()):\n",
    "        \n",
    "        update  = start + j.shape[0]//10\n",
    "        counter = Counter(Predictions_per_cond[cond][start:update])\n",
    "        start  += j.shape[0]//10\n",
    "        \n",
    "        for num in counter.keys():\n",
    "            Predictions_per_condition[cond][num+1].append(counter[num+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "clusters = []\n",
    "conditions = []\n",
    "for cond,v in Predictions_per_condition.items():\n",
    "    for cluster,i in v.items():\n",
    "        counts+=i\n",
    "        clusters+=list(np.repeat(cluster, len(i)))\n",
    "        conditions+=list(np.repeat(cond, len(i)))\n",
    "        \n",
    "Prediction_per_cond_df = pd.DataFrame({'condition':conditions,\n",
    "                                       'cluster':clusters,\n",
    "                                       'count':counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame=Prediction_per_cond_df, x='cluster', y='count', color='condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(Counter(labels[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(labels[0], labels[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ari_dist)\n",
    "plt.xlabel(\"Adjusted Rand Index\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(np.array([0.5,0,0.5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd.Categorical(np.array([0.5,0.5,0.5,0.5])).entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = np.array([0.5,0,0.5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.clip(np.log(pk), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.sum(pk*np.array([-0.69314718,        0, -0.69314718,        0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "entropy = K.sum(tf.multiply(pk, tf.where(~tf.math.is_inf(K.log(pk)), K.log(pk), 0)), axis=0)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.max(clusts, axis=1))\n",
    "sns.distplot(clusts.reshape(clusts.shape[0] * clusts.shape[1]))\n",
    "plt.axvline(1/10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_means = gmvaep.get_layer(name=\"dense_4\").get_weights()[0][:32]\n",
    "gauss_variances = tf.keras.activations.softplus(gmvaep.get_layer(name=\"dense_4\").get_weights()[0][32:]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_means.shape == gauss_variances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "n=100\n",
    "samples = []\n",
    "for i in range(k):\n",
    "    samples.append(np.random.normal(gauss_means[:,i], gauss_variances[:,i], size=(100,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "test_matrix = np.zeros([k,k])\n",
    "for i in range(k):\n",
    "    for j in range(k):\n",
    "        test_matrix[i][j] = np.mean(ttest_ind(samples[i], samples[j], equal_var=False)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.55\n",
    "np.sum(test_matrix > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treatment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection - the model was trained in the WT - NS mice alone\n",
    "gmvaep.load_weights(\"GMVAE_components=10_loss=ELBO_kl_warmup=20_mmd_warmup=5_20200721-043310_final_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_NS = table_dict({k:v for k,v in mtest2.items() if k in Treatment_dict['WT+NS']}, typ=\"coords\")\n",
    "WT_WS = table_dict({k:v for k,v in mtest2.items() if k in Treatment_dict['WT+CSDS']}, typ=\"coords\")\n",
    "MU_NS = table_dict({k:v for k,v in mtest2.items() if k in Treatment_dict['NatCre+NS']}, typ=\"coords\")\n",
    "MU_WS = table_dict({k:v for k,v in mtest2.items() if k in Treatment_dict['NatCre+CSDS']}, typ=\"coords\")\n",
    "\n",
    "preps = [WT_NS.preprocess(window_size=11, window_step=10, filter=\"gaussian\", sigma=55,shift=0, scale=\"standard\", align=True),\n",
    "         WT_WS.preprocess(window_size=11, window_step=10, filter=\"gaussian\", sigma=55,shift=0, scale=\"standard\", align=True),\n",
    "         MU_NS.preprocess(window_size=11, window_step=10, filter=\"gaussian\", sigma=55,shift=0, scale=\"standard\", align=True),\n",
    "         MU_WS.preprocess(window_size=11, window_step=10, filter=\"gaussian\", sigma=55,shift=0, scale=\"standard\", align=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [gmvaep.predict(i) for i in preps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "reconst_error = {k:mean_absolute_error(preps[i].reshape(preps[i].shape[0]*preps[i].shape[1],12).T, \n",
    "                                       preds[i].reshape(preds[i].shape[0]*preds[i].shape[1],12).T,\n",
    "                                       multioutput='raw_values') for i,k in enumerate(Treatment_dict.keys())}\n",
    "\n",
    "reconst_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconst_df = pd.concat([pd.DataFrame(np.concatenate([np.repeat(k, len(v)).reshape(len(v),1), v.reshape(len(v),1)],axis=1)) for k,v in reconst_error.items()])\n",
    "reconst_df = reconst_df.astype({0:str,1:float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=reconst_df, x=0, y=1, orient='vertical')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.ylim(0,0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check frame rates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
