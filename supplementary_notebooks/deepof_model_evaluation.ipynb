{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepOF model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset and a trained model, this notebook allows the user to \n",
    "\n",
    "* Load and inspect the different models (encoder, decoder, grouper, gmvaep)\n",
    "* Visualize reconstruction quality for a given model\n",
    "* Visualize a static latent space\n",
    "* Visualize trajectories on the latent space for a given video\n",
    "* sample from the latent space distributions and generate video clips showcasing generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(os.path.dirname(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepof.data\n",
    "import deepof.utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import umap\n",
    "\n",
    "from ipywidgets import interactive, interact, HBox, Layout, VBox\n",
    "from IPython import display\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define and run project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"..\", \"..\", \"Desktop\", \"deepof-data\", \"deepof_single_topview\")\n",
    "trained_network = \"./deepof_unsupervised_trained_models/trained_weights/\"\n",
    "exclude_bodyparts = tuple([\"\"])\n",
    "window_size = 15\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "proj = deepof.data.Project(\n",
    "    path=path, smooth_alpha=2, exclude_bodyparts=exclude_bodyparts, arena_dims=380,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "proj = proj.run(verbose=True)\n",
    "print(proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load pretrained deepof model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = proj.get_coords(center=\"Center\", align=\"Spine_1\", align_inplace=True)\n",
    "data_prep = coords.preprocess(test_videos=0, window_step=1, window_size=window_size, shuffle=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepof_weights = [i for i in os.listdir(trained_network) if i.endswith(\"h5\")][1]\n",
    "deepof_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters\n",
    "encoding = int(re.findall(\"encoding=(\\d+)_\", deepof_weights)[0])\n",
    "k = int(re.findall(\"k=(\\d+)_\", deepof_weights)[0])\n",
    "loss = re.findall(\"loss=(.+?)_\", deepof_weights)[0]\n",
    "NextSeqPred = float(re.findall(\"NSPred=(.+?)_\", deepof_weights)[0])\n",
    "PhenoPred = float(re.findall(\"PPred=(.+?)_\", deepof_weights)[0])\n",
    "RuleBasedPred = float(re.findall(\"RBPred=(.+?)_\", deepof_weights)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    grouper,\n",
    "    gmvaep,\n",
    "    prior,\n",
    "    posterior,\n",
    ") = deepof.models.GMVAE(\n",
    "    loss=loss,\n",
    "    number_of_components=k,\n",
    "    compile_model=True,\n",
    "    batch_size=batch_size,\n",
    "    encoding=encoding,\n",
    "    next_sequence_prediction=NextSeqPred,\n",
    "    phenotype_prediction=PhenoPred,\n",
    "    supervised_prediction=RuleBasedPred,\n",
    ").build(\n",
    "    data_prep.shape\n",
    ")\n",
    "#gmvaep.load_weights(os.path.join(trained_network, deepof_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to see model summaries\n",
    "# encoder.summary()\n",
    "# decoder.summary()\n",
    "# grouper.summary()\n",
    "gmvaep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to plot model structure\n",
    "def plot_model(model, name):\n",
    "    tf.keras.utils.plot_model(\n",
    "        model,\n",
    "        #to_fileos.path.join(\n",
    "        #    path,\n",
    "        #    \"deepof_{}_{}.png\".format(name, datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "        #),\n",
    "        show_shapes=True,\n",
    "        show_dtype=False,\n",
    "        show_layer_names=True,\n",
    "        rankdir=\"TB\",\n",
    "        expand_nested=True,\n",
    "        dpi=200,\n",
    "    )\n",
    "\n",
    "\n",
    "# plot_model(encoder, \"encoder\")\n",
    "# plot_model(decoder, \"decoder\")\n",
    "# plot_model(grouper, \"grouper\")\n",
    "plot_model(gmvaep, \"gmvaep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualize priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(number_of_components, encoding, init):\n",
    "\n",
    "    try:\n",
    "        prior = tfd.MixtureSameFamily(\n",
    "            mixture_distribution=tfd.categorical.Categorical(\n",
    "                probs=tf.ones(number_of_components) / number_of_components\n",
    "            ),\n",
    "            components_distribution=tfd.MultivariateNormalDiag(\n",
    "                loc=tf.Variable(\n",
    "                    init([number_of_components, encoding],),\n",
    "                    name=\"prior_means\",\n",
    "                ),\n",
    "                scale_diag=tf.ones([number_of_components, encoding]) / (1.5 * number_of_components),\n",
    "            ),\n",
    "        )\n",
    "    except TypeError:\n",
    "        prior = tfd.MixtureSameFamily(\n",
    "            mixture_distribution=tfd.categorical.Categorical(\n",
    "                probs=tf.ones(number_of_components) / number_of_components\n",
    "            ),\n",
    "            components_distribution=tfd.MultivariateNormalDiag(\n",
    "                loc=tf.Variable(\n",
    "                    init(num_results=number_of_components, dim=encoding,),\n",
    "                    name=\"prior_means\",\n",
    "                ),\n",
    "                scale_diag=tf.ones([number_of_components, encoding]) / (1.5 * number_of_components),\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_plot(prior, samples, ax, label):\n",
    "    \"\"\"Sample from the prior and plot with colours corresponding to different clusters\"\"\"\n",
    "    \n",
    "    samples = prior.sample(samples)\n",
    "    means = prior.components_distribution.mean()\n",
    "    samples = tf.concat([samples, means], axis=0)\n",
    "    pca = PCA(n_components=2)\n",
    "    prior = pca.fit_transform(samples)\n",
    "    \n",
    "    samples = prior[:-number_of_components, :]\n",
    "    means = prior[-number_of_components:, :]\n",
    "    \n",
    "    ax.scatter(prior[:,0], prior[:,1])\n",
    "    ax.scatter(means[:,0], means[:,1], label=label)\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 14:30:25.824363: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[ 0.13670844, -0.55144477, -0.11185074,  0.5059209 ,  0.15252686,\n",
       "         0.00488102,  0.44583452, -0.6772665 ,  0.35885406, -0.5891105 ],\n",
       "       [ 0.03394222, -0.53160405, -0.47305995,  0.09067482, -0.5867265 ,\n",
       "         0.18400049, -0.72696316,  0.6146749 , -0.54630464,  0.4942453 ],\n",
       "       [-0.39253008, -0.49482393,  0.16953743, -0.6142683 , -0.49529487,\n",
       "         0.11339283, -0.5551112 , -0.7558452 ,  0.69904995,  0.3064444 ],\n",
       "       [-0.68891907, -0.4951761 ,  0.20210409, -0.09580332, -0.21655482,\n",
       "        -0.4502718 , -0.08749223,  0.01265341, -0.34660727, -0.2340095 ],\n",
       "       [-0.00703293, -0.7057546 ,  0.5170778 , -0.51830137, -0.7549966 ,\n",
       "         0.08102852,  0.06454247,  0.16952872, -0.30610824, -0.3617642 ],\n",
       "       [ 0.42487562, -0.14894116,  0.3849516 ,  0.14983964, -0.18239194,\n",
       "        -0.04342192, -0.3840083 ,  0.01141423, -0.6928068 ,  0.7456689 ],\n",
       "       [ 0.04533166,  0.6727271 ,  0.07521278,  0.4046123 ,  0.34681118,\n",
       "         0.04136348,  0.12607723, -0.75180113,  0.30991054, -0.7170934 ],\n",
       "       [-0.62830126,  0.6785828 ,  0.49484682, -0.4748399 ,  0.07579654,\n",
       "        -0.7346814 , -0.07763487,  0.69619334, -0.09500843,  0.08523124],\n",
       "       [-0.26608056,  0.00992626, -0.5550379 ,  0.22574866,  0.48570633,\n",
       "         0.5095072 , -0.15905082, -0.5349059 ,  0.7175847 , -0.68020487],\n",
       "       [ 0.56459   , -0.2032783 , -0.6261878 , -0.04244977,  0.71688604,\n",
       "        -0.14906561,  0.13968396, -0.15892524,  0.38494742,  0.6652112 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.initializers.he_uniform()([10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658b0f48f6ad4fba9351485c8d257f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='i', max=16, min=1), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.manifold import Isomap\n",
    "import umap\n",
    "\n",
    "\n",
    "def far_uniform_initializer(shape, samples):\n",
    "    \n",
    "    init_shape = (samples, shape[1])\n",
    "    init_means = tf.keras.initializers.variance_scaling(scale=init_shape[0], distribution=\"uniform\")(init_shape)\n",
    "\n",
    "    final_samples, init_means = init_means[0][np.newaxis, :], init_means[1:]\n",
    "    \n",
    "    for i in range(shape[0] - 1):\n",
    "                \n",
    "        max_dist = cdist(final_samples, init_means, metric=\"euclidean\")\n",
    "        max_dist = np.argmax(np.min(max_dist, axis=0))\n",
    "        \n",
    "        final_samples = np.concatenate([final_samples, init_means[max_dist][np.newaxis, :]])\n",
    "        \n",
    "        init_means = np.delete(init_means, max_dist, 0)\n",
    "\n",
    "    return final_samples\n",
    "\n",
    "k = 16\n",
    "\n",
    "result = far_uniform_initializer([k, 6], 100000)\n",
    "\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "@interact()\n",
    "def plot_init(i=IntSlider(min=1, max=k)):\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    red = umap.UMAP(n_components=2).fit_transform(result)\n",
    "    plt.scatter(*red.T, label='result')\n",
    "    plt.scatter(*red[:i].T, label='result', s=200)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "number_of_components = 10\n",
    "encoding = 16\n",
    "\n",
    "initializers = [\n",
    "    partial(tfp.mcmc.sample_halton_sequence, dtype=tf.float32, randomized=False,\n",
    "    seed=None, name=\"GMVAE_prior_initialization\"\n",
    "    ),\n",
    "    tf.keras.initializers.GlorotNormal(),\n",
    "    tf.keras.initializers.GlorotUniform(),\n",
    "    tf.keras.initializers.HeNormal(),\n",
    "    tf.keras.initializers.HeUniform(),\n",
    "    tf.keras.initializers.LecunNormal(),\n",
    "    tf.keras.initializers.LecunUniform(),\n",
    "    tf.keras.initializers.Orthogonal(),\n",
    "    tf.keras.initializers.RandomNormal(),\n",
    "    tf.keras.initializers.RandomUniform(),\n",
    "    tf.keras.initializers.TruncatedNormal(),\n",
    "    tf.keras.initializers.VarianceScaling(),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(4, 3, figsize=(10, 15), sharex=False, sharey=False)\n",
    "ax = [item for sublist in ax for item in sublist]\n",
    "\n",
    "for i, x in enumerate(ax):\n",
    "    prior = get_prior(number_of_components, encoding, initializers[i])\n",
    "    try:\n",
    "        sample_and_plot(\n",
    "            prior,\n",
    "            1000,\n",
    "            x,\n",
    "            label=re.findall(\"initializers_v2.(.*?) \", str(initializers[i]))[0],\n",
    "        )\n",
    "    except IndexError:\n",
    "        sample_and_plot(\n",
    "            prior,\n",
    "            1000,\n",
    "            x,\n",
    "            label=\"Halton sequence\",\n",
    "        )\n",
    "\n",
    "fig.tight_layout(rect=[0.0, 0.0, 1.0, 0.97])\n",
    "plt.suptitle(\"effect of initialization on deepOF prior\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def quantify_separation(init, samples):\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    for i in range(samples):\n",
    "        means = get_prior(\n",
    "            number_of_components, encoding, init\n",
    "        ).components_distribution.mean()\n",
    "        mean_dist = np.mean(pdist(means))\n",
    "        distances.append(mean_dist)\n",
    "\n",
    "    return (\n",
    "        np.mean(distances),\n",
    "        np.min(distances),\n",
    "        np.max(distances),\n",
    "        1.96 * np.std(distances),\n",
    "    )\n",
    "\n",
    "\n",
    "prior_init_eval_dict = {}\n",
    "for init in tqdm.tqdm(initializers):\n",
    "    prior_init_eval_dict[\n",
    "        re.findall(\"initializers_v2.(.*?) \", str(init))[0]\n",
    "    ] = quantify_separation(init, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_init_eval = pd.DataFrame(prior_init_eval_dict).T\n",
    "prior_init_eval.rename(columns={0:\"mean\", 1:\"min\", 2:\"max\", 3:\"CI95\"}, inplace=True)\n",
    "prior_init_eval.sort_values(\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate reconstruction (to be incorporated into deepof.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary animation functions\n",
    "\n",
    "\n",
    "def plot_mouse_graph(instant_x, instant_y, instant_rec_x, instant_rec_y, ax, edges):\n",
    "    \"\"\"Generates a graph plot of the mouse\"\"\"\n",
    "    plots = []\n",
    "    rec_plots = []\n",
    "    for edge in edges:\n",
    "        (temp_plot,) = ax.plot(\n",
    "            [float(instant_x[edge[0]]), float(instant_x[edge[1]])],\n",
    "            [float(instant_y[edge[0]]), float(instant_y[edge[1]])],\n",
    "            color=\"#006699\",\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "        (temp_rec_plot,) = ax.plot(\n",
    "            [float(instant_rec_x[edge[0]]), float(instant_rec_x[edge[1]])],\n",
    "            [float(instant_rec_y[edge[0]]), float(instant_rec_y[edge[1]])],\n",
    "            color=\"red\",\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "        plots.append(temp_plot)\n",
    "        rec_plots.append(temp_rec_plot)\n",
    "    return plots, rec_plots\n",
    "\n",
    "\n",
    "def update_mouse_graph(x, y, rec_x, rec_y, plots, rec_plots, edges):\n",
    "    \"\"\"Updates the graph plot to enable animation\"\"\"\n",
    "\n",
    "    for plot, edge in zip(plots, edges):\n",
    "        plot.set_data(\n",
    "            [float(x[edge[0]]), float(x[edge[1]])],\n",
    "            [float(y[edge[0]]), float(y[edge[1]])],\n",
    "        )\n",
    "    for plot, edge in zip(rec_plots, edges):\n",
    "        plot.set_data(\n",
    "            [float(rec_x[edge[0]]), float(rec_x[edge[1]])],\n",
    "            [float(rec_y[edge[0]]), float(rec_y[edge[1]])],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display a video with the original data superimposed with the reconstructions\n",
    "\n",
    "coords = proj.get_coords(center=\"Center\", align=\"Spine_1\", align_inplace=True)\n",
    "random_exp = np.random.choice(list(coords.keys()), 1)[0]\n",
    "print(random_exp)\n",
    "\n",
    "\n",
    "def animate_mice_across_time(random_exp):\n",
    "\n",
    "    # Define canvas\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    # Retrieve body graph\n",
    "    edges = deepof.utils.connect_mouse_topview()\n",
    "\n",
    "    for bpart in exclude_bodyparts:\n",
    "        if bpart:\n",
    "            edges.remove_node(bpart)\n",
    "\n",
    "    for limb in [\"Left_fhip\", \"Right_fhip\", \"Left_bhip\", \"Right_bhip\"]:\n",
    "        edges.remove_edge(\"Center\", limb)\n",
    "        if (\"Tail_base\", limb) in edges.edges():\n",
    "            edges.remove_edge(\"Tail_base\", limb)\n",
    "\n",
    "    edges = edges.edges()\n",
    "\n",
    "    # Compute observed and predicted data to plot\n",
    "    data = coords[random_exp]\n",
    "    coords_rec = coords.filter_videos([random_exp])\n",
    "    data_prep = coords_rec.preprocess(\n",
    "        test_videos=0, window_step=1, window_size=window_size, shuffle=False\n",
    "    )[0][:512]\n",
    "\n",
    "    data_rec = gmvaep.predict(data_prep)\n",
    "    try:\n",
    "        data_rec = pd.DataFrame(coords_rec._scaler.inverse_transform(data_rec[:, 6, :]))\n",
    "    except TypeError:\n",
    "        data_rec = data_rec[0]\n",
    "        data_rec = pd.DataFrame(coords_rec._scaler.inverse_transform(data_rec[:, 6, :]))\n",
    "        \n",
    "    data_rec.columns = data.columns\n",
    "    data = pd.DataFrame(coords_rec._scaler.inverse_transform(data_prep[:, 6, :]))\n",
    "    data.columns = data_rec.columns\n",
    "\n",
    "    # Add Central coordinate, lost during alignment\n",
    "    data[\"Center\", \"x\"] = 0\n",
    "    data[\"Center\", \"y\"] = 0\n",
    "    data_rec[\"Center\", \"x\"] = 0\n",
    "    data_rec[\"Center\", \"y\"] = 0\n",
    "\n",
    "    # Plot!\n",
    "    init_x = data.xs(\"x\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "    init_y = data.xs(\"y\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "    init_rec_x = data_rec.xs(\"x\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "    init_rec_y = data_rec.xs(\"y\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "\n",
    "    plots, rec_plots = plot_mouse_graph(\n",
    "        init_x, init_y, init_rec_x, init_rec_y, ax, edges\n",
    "    )\n",
    "    scatter = ax.scatter(\n",
    "        x=np.array(init_x), y=np.array(init_y), color=\"#006699\", label=\"Original\"\n",
    "    )\n",
    "    rec_scatter = ax.scatter(\n",
    "        x=np.array(init_rec_x),\n",
    "        y=np.array(init_rec_y),\n",
    "        color=\"red\",\n",
    "        label=\"Reconstruction\",\n",
    "    )\n",
    "\n",
    "    # Update data in main plot\n",
    "    def animation_frame(i):\n",
    "        # Update scatter plot\n",
    "        x = data.xs(\"x\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        y = data.xs(\"y\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        rec_x = data_rec.xs(\"x\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        rec_y = data_rec.xs(\"y\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "\n",
    "        scatter.set_offsets(np.c_[np.array(x), np.array(y)])\n",
    "        rec_scatter.set_offsets(np.c_[np.array(rec_x), np.array(rec_y)])\n",
    "        update_mouse_graph(x, y, rec_x, rec_y, plots, rec_plots, edges)\n",
    "\n",
    "        return scatter\n",
    "\n",
    "    animation = FuncAnimation(fig, func=animation_frame, frames=250, interval=50,)\n",
    "\n",
    "    ax.set_title(\"Original versus reconstructed data\")\n",
    "    ax.set_ylim(-100, 60)\n",
    "    ax.set_xlim(-60, 60)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    plt.legend()\n",
    "\n",
    "    video = animation.to_html5_video()\n",
    "    html = display.HTML(video)\n",
    "    display.display(html)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "animate_mice_across_time(random_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate latent space (to be incorporated into deepof.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encodings and groupings for the same random video as above\n",
    "data_prep = coords.preprocess(\n",
    "    test_videos=0, window_step=1, window_size=window_size, shuffle=True\n",
    ")[0][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = encoder.predict(data_prep)\n",
    "groupings = grouper.predict(data_prep)\n",
    "hard_groups = np.argmax(groupings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(minimum_confidence=(0.0, 1.0, 0.01))\n",
    "def plot_cluster_population(minimum_confidence):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    groups = hard_groups[np.max(groupings, axis=1) > minimum_confidence].flatten()\n",
    "    groups = np.concatenate([groups, np.arange(groupings.shape[1])])\n",
    "    sns.countplot(groups)\n",
    "    plt.xlabel(\"Cluster\")\n",
    "    plt.title(\"Training instances per cluster\")\n",
    "    plt.ylim(0, hard_groups.shape[0] * 1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slider in the figure above lets you set the minimum confidence the model may yield when assigning a training instance to a cluster in order to be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot real data in the latent space\n",
    "\n",
    "samples = np.random.choice(range(encodings.shape[0]), 10000)\n",
    "sample_enc = encodings[samples, :]\n",
    "sample_grp = groupings[samples, :]\n",
    "sample_hgr = hard_groups[samples]\n",
    "k = sample_grp.shape[1]\n",
    "\n",
    "umap_reducer = umap.UMAP(n_components=2)\n",
    "pca_reducer = PCA(n_components=2)\n",
    "tsne_reducer = TSNE(n_components=2)\n",
    "lda_reducer = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "umap_enc = umap_reducer.fit_transform(sample_enc)\n",
    "pca_enc = pca_reducer.fit_transform(sample_enc)\n",
    "tsne_enc = tsne_reducer.fit_transform(sample_enc)\n",
    "try:\n",
    "    lda_enc = lda_reducer.fit_transform(sample_enc, sample_hgr)\n",
    "except ValueError:\n",
    "    warnings.warn(\n",
    "        \"Only one class found. Can't use LDA\", DeprecationWarning, stacklevel=2\n",
    "    )\n",
    "\n",
    "\n",
    "@interact(\n",
    "    minimum_confidence=(0.0, 0.99, 0.01),\n",
    "    dim_red=[\"PCA\", \"LDA\", \"umap\", \"tSNE\"],\n",
    "    highlight_clusters=False,\n",
    "    selected_cluster=(0, k-1),\n",
    ")\n",
    "def plot_static_latent_space(\n",
    "    minimum_confidence, dim_red, highlight_clusters, selected_cluster\n",
    "):\n",
    "\n",
    "    global sample_enc, sample_grp, sample_hgr\n",
    "\n",
    "    if dim_red == \"umap\":\n",
    "        enc = umap_enc\n",
    "    elif dim_red == \"LDA\":\n",
    "        enc = lda_enc\n",
    "    elif dim_red == \"PCA\":\n",
    "        enc = pca_enc\n",
    "    else:\n",
    "        enc = tsne_enc\n",
    "\n",
    "    enc = enc[np.max(sample_grp, axis=1) > minimum_confidence]\n",
    "    hgr = sample_hgr[np.max(sample_grp, axis=1) > minimum_confidence].flatten()\n",
    "    grp = sample_grp[np.max(sample_grp, axis=1) > minimum_confidence]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=enc[:, 0],\n",
    "        y=enc[:, 1],\n",
    "        hue=hgr,\n",
    "        size=np.max(grp, axis=1),\n",
    "        sizes=(1, 100),\n",
    "        palette=sns.color_palette(\"husl\", len(set(hgr))),\n",
    "    )\n",
    "    \n",
    "    if highlight_clusters:\n",
    "        sns.kdeplot(\n",
    "            enc[hgr == selected_cluster, 0],\n",
    "            enc[hgr == selected_cluster, 1],\n",
    "            color=\"red\",\n",
    "        )\n",
    "    \n",
    "    plt.xlabel(\"{} 1\".format(dim_red))\n",
    "    plt.ylabel(\"{} 2\".format(dim_red))\n",
    "    plt.suptitle(\"Static view of trained latent space\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mouse_graph(instant_x, instant_y, ax, edges):\n",
    "    \"\"\"Generates a graph plot of the mouse\"\"\"\n",
    "    plots = []\n",
    "    for edge in edges:\n",
    "        (temp_plot,) = ax.plot(\n",
    "            [float(instant_x[edge[0]]), float(instant_x[edge[1]])],\n",
    "            [float(instant_y[edge[0]]), float(instant_y[edge[1]])],\n",
    "            color=\"#006699\",\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "        plots.append(temp_plot)\n",
    "    return plots\n",
    "\n",
    "\n",
    "def update_mouse_graph(x, y, plots, edges):\n",
    "    \"\"\"Updates the graph plot to enable animation\"\"\"\n",
    "\n",
    "    for plot, edge in zip(plots, edges):\n",
    "        plot.set_data(\n",
    "            [float(x[edge[0]]), float(x[edge[1]])],\n",
    "            [float(y[edge[0]]), float(y[edge[1]])],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot trajectory of a video in latent space\n",
    "traj_prep = coords.preprocess(\n",
    "    test_videos=0, window_step=1, window_size=window_size, shuffle=False\n",
    ")[0][:10000]\n",
    "\n",
    "traj_encodings = encoder.predict(traj_prep)\n",
    "traj_grp = grouper.predict(traj_prep)\n",
    "traj_hgr = np.argmax(traj_grp, axis=1)\n",
    "\n",
    "samples = np.random.choice(range(encodings.shape[0]), 10000)\n",
    "sample_enc = encodings[samples, :]\n",
    "sample_grp = groupings[samples, :]\n",
    "sample_hgr = hard_groups[samples]\n",
    "k = sample_grp.shape[1]\n",
    "\n",
    "umap_reducer = umap.UMAP(n_components=2)\n",
    "pca_reducer = PCA(n_components=2)\n",
    "tsne_reducer = TSNE(n_components=2)\n",
    "lda_reducer = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "umap_enc = umap_reducer.fit_transform(np.concatenate([traj_encodings, sample_enc]))\n",
    "pca_enc = pca_reducer.fit_transform(np.concatenate([traj_encodings, sample_enc]))\n",
    "tsne_enc = tsne_reducer.fit_transform(np.concatenate([traj_encodings, sample_enc]))\n",
    "try:\n",
    "    lda_enc = lda_reducer.fit_transform(\n",
    "        np.concatenate([traj_encodings, sample_enc]),\n",
    "        np.concatenate([traj_hgr, sample_hgr]),\n",
    "    )\n",
    "except ValueError:\n",
    "    warnings.warn(\n",
    "        \"Only one class found. Can't use LDA\", DeprecationWarning, stacklevel=2\n",
    "    )\n",
    "\n",
    "\n",
    "@interact(\n",
    "    trajectory=(100, 1500), trace=False, dim_red=[\"PCA\", \"LDA\", \"umap\", \"tSNE\"],\n",
    ")\n",
    "def plot_dynamic_latent_pace(trajectory, trace, dim_red):\n",
    "\n",
    "    global sample_enc, sample_grp, sample_hgr\n",
    "\n",
    "    if dim_red == \"umap\":\n",
    "        enc, traj_enc = umap_enc[10000:], umap_enc[:10000]\n",
    "    elif dim_red == \"LDA\":\n",
    "        enc, traj_enc = lda_enc[10000:], lda_enc[:10000]\n",
    "    elif dim_red == \"PCA\":\n",
    "        enc, traj_enc = pca_enc[10000:], pca_enc[:10000]\n",
    "    else:\n",
    "        enc, traj_enc = tsne_enc[10000:], tsne_enc[:10000]\n",
    "\n",
    "    traj_enc = traj_enc[:trajectory, :]\n",
    "\n",
    "    # Define two figures arranged horizontally\n",
    "    fig, (ax, ax2) = plt.subplots(\n",
    "        1, 2, figsize=(12, 8), gridspec_kw={\"width_ratios\": [3, 1.5]}\n",
    "    )\n",
    "\n",
    "    # Plot the animated embedding trajectory on the left\n",
    "    sns.scatterplot(\n",
    "        x=enc[:, 0],\n",
    "        y=enc[:, 1],\n",
    "        hue=sample_hgr,\n",
    "        size=np.max(sample_grp, axis=1),\n",
    "        sizes=(1, 100),\n",
    "        palette=sns.color_palette(\"husl\", len(set(sample_hgr))),\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    traj_init = traj_enc[0, :]\n",
    "    scatter = ax.scatter(\n",
    "        x=[traj_init[0]], y=[traj_init[1]], s=100, color=\"red\", edgecolor=\"black\"\n",
    "    )\n",
    "    (lineplt,) = ax.plot([traj_init[0]], [traj_init[1]], color=\"red\", linewidth=2.0)\n",
    "    tracking_line_x = []\n",
    "    tracking_line_y = []\n",
    "\n",
    "    # Plot the initial data (before feeding it to the encoder) on the right\n",
    "    edges = deepof.utils.connect_mouse_topview()\n",
    "\n",
    "    for bpart in exclude_bodyparts:\n",
    "        if bpart:\n",
    "            edges.remove_node(bpart)\n",
    "\n",
    "    for limb in [\"Left_fhip\", \"Right_fhip\", \"Left_bhip\", \"Right_bhip\"]:\n",
    "        edges.remove_edge(\"Center\", limb)\n",
    "        if (\"Tail_base\", limb) in list(edges.edges()):\n",
    "            edges.remove_edge(\"Tail_base\", limb)\n",
    "\n",
    "    edges = edges.edges()\n",
    "\n",
    "    inv_coords = coords._scaler.inverse_transform(traj_prep)[:, window_size // 2, :]\n",
    "    data = pd.DataFrame(inv_coords, columns=coords[random_exp].columns)\n",
    "\n",
    "    data[\"Center\", \"x\"] = 0\n",
    "    data[\"Center\", \"y\"] = 0\n",
    "\n",
    "    init_x = data.xs(\"x\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "    init_y = data.xs(\"y\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "\n",
    "    plots = plot_mouse_graph(init_x, init_y, ax2, edges)\n",
    "    track = ax2.scatter(x=np.array(init_x), y=np.array(init_y), color=\"#006699\",)\n",
    "\n",
    "    # Update data in both plots\n",
    "    def animation_frame(i):\n",
    "        # Update scatter plot\n",
    "        offset = traj_enc[i, :]\n",
    "\n",
    "        prev_t = scatter.get_offsets()[0]\n",
    "\n",
    "        if trace:\n",
    "            tracking_line_x.append([prev_t[0], offset[0]])\n",
    "            tracking_line_y.append([prev_t[1], offset[1]])\n",
    "            lineplt.set_xdata(tracking_line_x)\n",
    "            lineplt.set_ydata(tracking_line_y)\n",
    "\n",
    "        scatter.set_offsets(np.c_[np.array(offset[0]), np.array(offset[1])])\n",
    "\n",
    "        x = data.xs(\"x\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        y = data.xs(\"y\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        track.set_offsets(np.c_[np.array(x), np.array(y)])\n",
    "        update_mouse_graph(x, y, plots, edges)\n",
    "\n",
    "        return scatter\n",
    "\n",
    "    animation = FuncAnimation(\n",
    "        fig, func=animation_frame, frames=trajectory, interval=75,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"{} 1\".format(dim_red))\n",
    "    ax.set_ylabel(\"{} 2\".format(dim_red))\n",
    "    ax2.set_ylim(-90, 60)\n",
    "    ax2.set_xlim(-60, 60)\n",
    "    \n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_xlabel(\"y\")\n",
    "    ax2.set_ylim(-90, 60)\n",
    "    ax2.set_xlim(-60, 60)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    video = animation.to_html5_video()\n",
    "    html = display.HTML(video)\n",
    "    display.display(html)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Sample from latent space (to be incorporated into deepof.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prior distribution\n",
    "\n",
    "means = prior.components_distribution.mean().numpy()\n",
    "stddevs = prior.components_distribution.stddev().numpy()\n",
    "\n",
    "samples = []\n",
    "for i in range(means.shape[0]):\n",
    "    samples.append(\n",
    "        np.random.normal(means[i, :], stddevs[i, :], size=(500, means.shape[1]))\n",
    "    )\n",
    "samples = np.concatenate(samples)\n",
    "decodings = decoder.predict(samples)\n",
    "\n",
    "umap_reducer = umap.UMAP(n_components=2)\n",
    "pca_reducer = PCA(n_components=2)\n",
    "tsne_reducer = TSNE(n_components=2)\n",
    "lda_reducer = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "umap_enc = umap_reducer.fit_transform(samples)\n",
    "pca_enc = pca_reducer.fit_transform(samples)\n",
    "tsne_enc = tsne_reducer.fit_transform(samples)\n",
    "lda_enc = lda_reducer.fit_transform(samples, np.repeat(range(means.shape[0]), 500))\n",
    "\n",
    "\n",
    "@interact(dim_red=[\"PCA\", \"LDA\", \"umap\", \"tSNE\"], selected_cluster=(1, k))\n",
    "def sample_from_prior(dim_red, selected_cluster):\n",
    "\n",
    "    if dim_red == \"umap\":\n",
    "        sample_enc = umap_enc\n",
    "    elif dim_red == \"LDA\":\n",
    "        sample_enc = lda_enc\n",
    "    elif dim_red == \"PCA\":\n",
    "        sample_enc = pca_enc\n",
    "    else:\n",
    "        sample_enc = tsne_enc\n",
    "\n",
    "    fig, (ax, ax2) = plt.subplots(\n",
    "        1, 2, figsize=(12, 8), gridspec_kw={\"width_ratios\": [3, 1.5]}\n",
    "    )\n",
    "\n",
    "    hue = np.repeat(range(means.shape[0]), 500)\n",
    "\n",
    "    # Plot the animated embedding trajectory on the left\n",
    "    sns.scatterplot(\n",
    "        x=sample_enc[:, 0],\n",
    "        y=sample_enc[:, 1],\n",
    "        hue=hue,\n",
    "        palette=sns.color_palette(\"husl\", k),\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    sns.kdeplot(\n",
    "        sample_enc[hue == selected_cluster, 0],\n",
    "        sample_enc[hue == selected_cluster, 1],\n",
    "        color=\"red\",\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # Get reconstructions from samples of a given cluster\n",
    "    decs = decodings[hue == selected_cluster][np.random.randint(0, 500, 5)]\n",
    "\n",
    "    # Plot the initial data (before feeding it to the encoder) on the right\n",
    "    edges = deepof.utils.connect_mouse_topview()\n",
    "\n",
    "    for bpart in exclude_bodyparts:\n",
    "        if bpart:\n",
    "            edges.remove_node(bpart)\n",
    "\n",
    "    for limb in [\"Left_fhip\", \"Right_fhip\", \"Left_bhip\", \"Right_bhip\"]:\n",
    "        edges.remove_edge(\"Center\", limb)\n",
    "        if (\"Tail_base\", limb) in list(edges.edges()):\n",
    "            edges.remove_edge(\"Tail_base\", limb)\n",
    "\n",
    "    edges = edges.edges()\n",
    "\n",
    "    inv_coords = coords._scaler.inverse_transform(decs).reshape(\n",
    "        decs.shape[0] * decs.shape[1], decs.shape[2]\n",
    "    )\n",
    "    data = pd.DataFrame(inv_coords, columns=coords[random_exp].columns)\n",
    "\n",
    "    data[\"Center\", \"x\"] = 0\n",
    "    data[\"Center\", \"y\"] = 0\n",
    "\n",
    "    init_x = data.xs(\"x\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "    init_y = data.xs(\"y\", level=1, axis=1, drop_level=False).iloc[0, :]\n",
    "\n",
    "    plots = plot_mouse_graph(init_x, init_y, ax2, edges)\n",
    "    track = ax2.scatter(x=np.array(init_x), y=np.array(init_y), color=\"#006699\",)\n",
    "\n",
    "    # Update data in both plots\n",
    "    def animation_frame(i):\n",
    "        # Update scatter plot\n",
    "\n",
    "        x = data.xs(\"x\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        y = data.xs(\"y\", level=1, axis=1, drop_level=False).iloc[i, :]\n",
    "        track.set_offsets(np.c_[np.array(x), np.array(y)])\n",
    "        update_mouse_graph(x, y, plots, edges)\n",
    "\n",
    "    animation = FuncAnimation(\n",
    "        fig, func=animation_frame, frames=5 * window_size, interval=50,\n",
    "    )\n",
    "\n",
    "    # Plot samples as video on the right\n",
    "\n",
    "    ax.set_xlabel(\"{} 1\".format(dim_red))\n",
    "    ax.set_ylabel(\"{} 2\".format(dim_red))\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_xlabel(\"y\")\n",
    "    ax2.set_ylim(-90, 60)\n",
    "    ax2.set_xlim(-60, 60)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    video = animation.to_html5_video()\n",
    "    html = display.HTML(video)\n",
    "    display.display(html)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
